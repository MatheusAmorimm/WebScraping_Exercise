
# ğŸ“š Books to Scrape - Web Scraper

Projeto de web scraping desenvolvido em Python para extrair dados do site [Books to Scrape](http://books.toscrape.com), um site de demonstraÃ§Ã£o para prÃ¡ticas de scraping. O script coleta informaÃ§Ãµes sobre livros e exporta os dados para um arquivo CSV.

---

## ğŸ“Œ Objetivo

O objetivo do projeto Ã© automatizar a coleta de dados de livros disponÃ­veis no site, extraindo informaÃ§Ãµes como:

- TÃ­tulo
- PreÃ§o
- NÃºmero de estrelas (avaliaÃ§Ã£o)
- Estoque
- GÃªnero (categoria)
- DescriÃ§Ã£o

---

## ğŸ§  Tecnologias e Bibliotecas Utilizadas

- `Python 3`
- `requests`
- `BeautifulSoup (bs4)`
- `pandas`
- `concurrent.futures` (ThreadPoolExecutor e ProcessPoolExecutor)

---

## ğŸ“ Estrutura do Projeto

```
desafio/
â”‚
â”œâ”€â”€ main.py        # Arquivo principal que orquestra a coleta e exportaÃ§Ã£o dos dados
â”œâ”€â”€ scraping/
    â””â”€â”€ pages.py                 # LÃª e processa cada pÃ¡gina do site
    â””â”€â”€ book_info.py             # Extrai informaÃ§Ãµes detalhadas de cada livro
    â””â”€â”€ utils.py                 # DicionÃ¡rio de conversÃ£o de estrelas
â””â”€â”€ data/
    â””â”€â”€ books.csv            # Arquivo gerado com os dados coletados
```

---

## ğŸš€ Como Executar o Projeto

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/books-scraper.git
cd books-scraper
```

### 2. Crie e ative um ambiente virtual (opcional, mas recomendado)

```bash
python -m venv venv
source venv/bin/activate      # Linux/Mac
venv\Scripts\activate       # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Execute o script principal

```bash
python main.py
```

ApÃ³s a execuÃ§Ã£o, o arquivo `books.csv` serÃ¡ salvo na pasta `data/`.

---

## ğŸ§  Como Funciona

- `main.py` gera URLs das 50 pÃ¡ginas do site e processa cada uma em paralelo com `ProcessPoolExecutor`.
- `readPage()` em `pages.py` busca e analisa todos os livros da pÃ¡gina usando `ThreadPoolExecutor` para acelerar o scraping individual dos livros.
- `fetchBookData()` em `book_info.py` extrai os dados bÃ¡sicos do livro, e chama `readBookInfo()` para pegar o gÃªnero e a descriÃ§Ã£o acessando a pÃ¡gina individual do livro.
- `utils.py` contÃ©m um dicionÃ¡rio auxiliar para converter avaliaÃ§Ãµes por estrelas (texto) em nÃºmeros.

---

## ğŸ“Š Exemplo de Dados Coletados

| Titles              | Prices | Stars | Gender  | Stock     | Descriptions              |
|---------------------|--------|-------|---------|-----------|----------------------------|
| A Light in the Attic | 51.77  | 3     | Poetry  | In stock  | It's hard to imagine...    |
| Tipping the Velvet   | 53.74  | 1     | Fiction | In stock  | Tipping the Velvet is...   |

---

## â±ï¸ Desempenho

- A coleta foi otimizada com `concurrent.futures` para paralelizar:
  - o scraping de pÃ¡ginas (`multiprocessamento`)
  - o scraping de livros dentro da pÃ¡gina (`multithread`)
- HÃ¡ um `sleep` aleatÃ³rio entre 1-3 segundos nas requisiÃ§Ãµes de detalhes para evitar bloqueios pelo servidor.

---

## ğŸ›¡ï¸ Boas PrÃ¡ticas

- User-Agent personalizado nas requisiÃ§Ãµes
- Tratamento de exceÃ§Ãµes com `try/except`
- CÃ³digos organizados por responsabilidade (modularizaÃ§Ã£o)
- Evita scraping agressivo (uso de delays aleatÃ³rios)

---

## ğŸ“Œ LicenÃ§a

Este projeto Ã© apenas para fins educacionais. O site alvo Ã© pÃºblico e voltado para testes de scraping. Nenhuma informaÃ§Ã£o real ou privada estÃ¡ sendo coletada.

---

## âœï¸ Autor

Desenvolvido por Matheus Amorim  
ğŸ’¼ GitHub: [https://github.com/MatheusAmorimm](https://github.com/MatheusAmorimm)

---
